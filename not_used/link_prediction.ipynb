{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G7c18JmeSuZW"
      },
      "source": [
        "This work is inspired/based in the following repositories: \n",
        "\n",
        "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py\n",
        "\n",
        "https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/blob/main/Chapter10/chapter10.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O90RfNPbNn8g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Reddit\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import SAGEConv\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "import copy\n",
        "from tqdm import tqdm \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "# Local \n",
        "import graph_handler\n",
        "import graph_sage_node_classification\n",
        "from k_cross_validation import k_fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.backends.mps.is_available() and False:\n",
        "    device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=device)\n",
        "    print (x)\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read in Data: CORA - small version "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "data = data.to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Information from graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Cora()\n",
            "-------------------\n",
            "Number of graphs: 1\n",
            "Number of nodes: 2708\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "\n",
            "Graph:\n",
            "------\n",
            "Training nodes: 140\n",
            "Evaluation nodes: 500\n",
            "Test nodes: 1000\n",
            "Edges are directed: False\n",
            "Graph has isolated nodes: False\n",
            "Graph has loops: False\n"
          ]
        }
      ],
      "source": [
        "graph_handler.visualize_information_graph(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2708"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.num_nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PARAMETERS TO CHANGE FOR EXPERIMENTS \n",
        "learning_rate = 0.0001\n",
        "aggregator = 'mean'\n",
        "\n",
        "# FIXED PARAMETERS\n",
        "epochs = 10\n",
        "dropout_rate = 0.4\n",
        "normalization = True\n",
        "activation_function = True\n",
        "bias = True\n",
        "batch =  512\n",
        "neighborhood_1 = 25\n",
        "neighborhood_2 = 10\n",
        "embedding_dimension = 128\n",
        "k = 5 # k-cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training model and obtaining results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store the metrics for each fold\n",
        "micro_f1_scores, macro_f1_scores, accuracy_scores = [], [], []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split data \n",
        "https://medium.com/stanford-cs224w/a-tour-of-pygs-data-loaders-9f2384e48f8f\n",
        "\n",
        "https://zqfang.github.io/2021-08-12-graph-linkpredict/ --> trasductie disjoint mode "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = RandomLinkSplit(\n",
        "    num_val=0.2,  # fraction of data held out for validation\n",
        "    num_test=0.2, # fraction of data held out for test\n",
        "    is_undirected= True, \n",
        "    add_negative_train_samples= True, \n",
        "    neg_sampling_ratio= 1.0, # Need to include negative sampling edges, the edges not existed in the original graph.\n",
        "    key = 'edge_label', \n",
        "    disjoint_train_ratio = 0.9\n",
        ")\n",
        "train_data, val_data, test_data = transform(data)\n",
        "train_data, val_data, test_data =  train_data.to(device), val_data.to(device), test_data.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NeighborLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = LinkNeighborLoader(train_data, \n",
        "                            num_neighbors=[neighborhood_1, neighborhood_2],\n",
        "                            shuffle=True,\n",
        "                            neg_sampling_ratio= 1.0, \n",
        "                            batch_size = batch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Information from sampling/subgraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print each subgraph\n",
        "for i, subgraph in enumerate(train_loader):\n",
        "    print(f'Subgraph {i}: {subgraph}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Make model for Link prediction\n",
        "\n",
        "Initialization:\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html\n",
        "\n",
        "https://medium.com/@juyi.lin/neighborloader-introduction-ccb870cc7294\n",
        "\n",
        "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphSAGE_local(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout, aggr='mean', normalization = True, activation_function = True, bias = True):\n",
        "\n",
        "        super().__init__()\n",
        "        # as K = 2, we have 2 layers\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, out_channels = hidden_channels, project = activation_function, bias = bias)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels = out_channels, project = activation_function, bias = bias, normalize = normalization)\n",
        "        #self.conv3 = SAGEConv(128, out_channels = out_channels, normalize = normalization, project = activation_function, bias = bias)\n",
        "\n",
        "    def forward(self, matrix_nodes_features, edge_index):\n",
        "      # matrix_nodes_features is a matrix from the data where row = nodes, columns = feature\n",
        "      # edge_index: This is a tensor that describes the connectivity of the graph. Each column in this matrix represents an edge. The first row contains the indices of the source nodes, and the second row contains the indices of the target nodes.\n",
        "    \n",
        "        x = self.conv1(matrix_nodes_features, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "\n",
        "        #x = self.conv3(x, edge_index)\n",
        "        #x = F.relu(x)\n",
        "        #x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        # returning only x allows to apply any task-specific post-processing (in this case: link prediction and node classification)\n",
        "        return x \n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm-wlKeK5VkW"
      },
      "source": [
        "# Train model with unsupervised loss \n",
        "Where model is trainned to fit training data \n",
        " The function iterates over batches of data from train_loader. Each batch contains a subset of the entire training dataset\n",
        " \n",
        " For each batch, the model computes the node embeddings h, then calculates the embeddings for the source h_src and destination h_dst nodes of each edge. It then predicts whether an edge should exist between node pairs (pred)\n",
        "\n",
        "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, device):\n",
        "    model.train() # set model into training mode, doesnt do anything else \n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        h = model(data.x, data.edge_index)\n",
        "        h_src = h[data.edge_label_index[0]]\n",
        "        h_dst = h[data.edge_label_index[1]]\n",
        "        \n",
        "        pred = (h_src * h_dst).sum(dim=-1)\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, data.edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.size(0)\n",
        "\n",
        "    return total_loss / len(train_loader)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test method\n",
        "The test function evaluates the model's performance on unseen data. \n",
        "\n",
        "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    train_acc = clf.score(out[data.train_mask], data.y[data.train_mask]) \n",
        "    val_acc = clf.score(out[data.val_mask], data.y[data.val_mask]) \n",
        "    test_acc = clf.score(out[data.test_mask], data.y[data.test_mask])\n",
        "    return train_acc, val_acc, test_acc\n",
        "\n",
        "# TODO: this test maybe should return other things "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Running code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create GraphSAGE model for link prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GraphSAGE_local(\n",
            "  (conv1): SAGEConv(1433, 1433, aggr=mean)\n",
            "  (conv2): SAGEConv(1433, 128, aggr=mean)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = GraphSAGE_local(in_channels = data.num_node_features,\n",
        "                  hidden_channels= data.num_node_features,\n",
        "                  out_channels = embedding_dimension,\n",
        "                  dropout= dropout_rate,\n",
        "                  aggr = aggregator,\n",
        "                  normalization = normalization,\n",
        "                  activation_function = activation_function,\n",
        "                  bias = bias)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Training model for certain number for epochs and testing it "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch   0 | Train Loss: 441.883 | Train Acc:  82.14% | Val Acc: 32.40% | Test Acc: 31.60%\n",
            "Epoch   1 | Train Loss: 410.926 | Train Acc:  81.43% | Val Acc: 34.20% | Test Acc: 33.70%\n",
            "Epoch   2 | Train Loss: 393.371 | Train Acc:  83.57% | Val Acc: 34.80% | Test Acc: 35.30%\n",
            "Epoch   3 | Train Loss: 370.712 | Train Acc:  83.57% | Val Acc: 35.40% | Test Acc: 37.80%\n",
            "Epoch   4 | Train Loss: 361.608 | Train Acc:  85.00% | Val Acc: 34.40% | Test Acc: 38.40%\n",
            "Epoch   5 | Train Loss: 352.054 | Train Acc:  85.00% | Val Acc: 36.40% | Test Acc: 39.80%\n",
            "Epoch   6 | Train Loss: 343.511 | Train Acc:  84.29% | Val Acc: 36.40% | Test Acc: 41.00%\n",
            "Epoch   7 | Train Loss: 340.351 | Train Acc:  83.57% | Val Acc: 38.00% | Test Acc: 41.40%\n",
            "Epoch   8 | Train Loss: 340.431 | Train Acc:  84.29% | Val Acc: 38.20% | Test Acc: 42.50%\n",
            "Epoch   9 | Train Loss: 335.183 | Train Acc:  85.00% | Val Acc: 38.20% | Test Acc: 43.30%\n",
            "Epoch  10 | Train Loss: 337.397 | Train Acc:  86.43% | Val Acc: 37.40% | Test Acc: 43.70%\n",
            "Median time per epoch: 0.3056s\n"
          ]
        }
      ],
      "source": [
        "times = []\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs+1):\n",
        "    start = time.time()\n",
        "\n",
        "    loss = train(model, optimizer, train_loader, device)\n",
        "\n",
        "    train_acc, val_acc, test_acc = test(model, data)\n",
        "    \n",
        "    print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {train_acc*100:>6.2f}% | Val Acc: {val_acc*100:.2f}% | Test Acc: {test_acc*100:.2f}%')\n",
        "    \n",
        "    times.append(time.time() - start)\n",
        "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data(x=[2423, 1433], edge_index=[2, 7907], y=[2423], train_mask=[2423], val_mask=[2423], test_mask=[2423], n_id=[2423], e_id=[7907], input_id=[256], edge_label_index=[2, 512], edge_label=[512])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JxEm6MvHzmAR",
        "DGzwcEMn5aWa"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
