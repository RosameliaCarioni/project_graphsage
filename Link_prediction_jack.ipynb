{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bjYrUL9V7LV"
      },
      "source": [
        "#Link prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "57O237suPDmh"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6GyUHVcQXpl",
        "outputId": "646b4e29-9d8a-4e82-801c-39b927166f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "0rKhx5puPFJ-"
      },
      "outputs": [],
      "source": [
        "def load_embedding(file):\n",
        "    # Load NetMF embedding from .npy file\n",
        "    return np.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "QwKYGGFBPOBe"
      },
      "outputs": [],
      "source": [
        "def link_prediction(embedding, edges, non_edges):\n",
        "\n",
        "    # Extract embeddings for the given edges and non-edges\n",
        "    emb_edges = np.array([embedding[edge[0]] * embedding[edge[1]] for edge in edges])\n",
        "    emb_non_edges = np.array([embedding[non_edge[0]] * embedding[non_edge[1]] for non_edge in non_edges])\n",
        "\n",
        "    print('iteration done')\n",
        "\n",
        "    # Label the edges as 1 and non-edges as 0\n",
        "    labels = np.concatenate([np.ones(len(edges)), np.zeros(len(non_edges))])\n",
        "\n",
        "    # Combine edge and non-edge embeddings\n",
        "    X = np.concatenate([emb_edges, emb_non_edges])\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.5, random_state=42)\n",
        "\n",
        "    print('split done')\n",
        "\n",
        "    # Normalize the inner product by the sigmoid function\n",
        "    inner_product = np.sum(X_test, axis=1)\n",
        "    normalized_similarity = 1 / (1 + np.exp(-inner_product))\n",
        "\n",
        "    print('similarities calculated')\n",
        "\n",
        "    # Compute ROC-AUC score\n",
        "    roc_auc = roc_auc_score(y_test, normalized_similarity)\n",
        "\n",
        "    return roc_auc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rEXXBJ0S87T"
      },
      "source": [
        "#Sample edges and non-edges for karate club"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "96hJgkU8S7nY"
      },
      "outputs": [],
      "source": [
        "# # Generate the karate club graph\n",
        "# karate_club_graph = nx.karate_club_graph()\n",
        "\n",
        "# # Get the edges and non-edges\n",
        "# edges = list(karate_club_graph.edges())\n",
        "# all_possible_edges = list(nx.non_edges(karate_club_graph))\n",
        "\n",
        "# # Sample an equal number of non-edges for a balanced dataset\n",
        "# non_edges = np.random.choice(range(len(all_possible_edges)), size=len(edges), replace=False)\n",
        "# non_edges = [all_possible_edges[i] for i in non_edges]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M1Sz6EsTCD0"
      },
      "source": [
        "#Sample edges and non-edges for other datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0SVILD68THBH"
      },
      "outputs": [],
      "source": [
        "# Set parameters directly\n",
        "folder_path = \"datasets/BlogCatalog-dataset/\"\n",
        "\n",
        "nodes_file = folder_path + \"data/nodes.csv\"\n",
        "edges_file = folder_path + \"data/edges.csv\"\n",
        "groups_file = folder_path + \"data/groups.csv\"\n",
        "group_edges_file = folder_path + \"data/group-edges.csv\"\n",
        "output_file = \"/content/drive/MyDrive/NetMF_implementations/output_blogcatalog_large\"\n",
        "\n",
        "nodes_id = pd.read_csv(nodes_file, header=None, names=['id'])\n",
        "groups_id = pd.read_csv(groups_file, header=None, names=['group'])\n",
        "edges = pd.read_csv(edges_file, header=None, names=['id_1', 'id_2'])\n",
        "user_group_membership = pd.read_csv(group_edges_file, header=None, names=['id', 'group'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load edges from the edges.csv file\n",
        "edges_df = pd.read_csv(edges_file, header=None, names=['node1', 'node2'])\n",
        "\n",
        "# Adjust node indices to start from 0\n",
        "edges_df['node1'] -= 1\n",
        "edges_df['node2'] -= 1\n",
        "\n",
        "# Create a graph using the edges\n",
        "graph = nx.Graph()\n",
        "graph.add_edges_from(edges_df.values)\n",
        "\n",
        "# Get the edges and non-edges\n",
        "edges = list(graph.edges())\n",
        "all_possible_edges = list(nx.non_edges(graph))\n",
        "\n",
        "# Sample an equal number of non-edges for a balanced dataset\n",
        "non_edges = np.random.choice(range(len(all_possible_edges)), size=len(edges), replace=False)\n",
        "non_edges = [all_possible_edges[i] for i in non_edges]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52829533"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_possible_edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mB9V0vEROQH",
        "outputId": "95857d2d-5a13-4beb-d82f-f7c94c4bfa97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration done\n",
            "split done\n",
            "similarities calculated\n",
            "ROC-AUC Score: 0.6652234954734094\n"
          ]
        }
      ],
      "source": [
        "# Replace 'netmf_embedding.npy' with the actual path to your NetMF embedding file\n",
        "embedding_file = '/content/drive/MyDrive/NetMF_implementations/output_blogcatalog_large.npy'\n",
        "netmf_embedding = load_embedding(embedding_file)\n",
        "\n",
        "# # Example: Assume 'edges' contains positive examples and 'non_edges' contains negative examples\n",
        "# edges = [(0, 1), (2, 3), ...]  # Replace with your actual positive examples\n",
        "# non_edges = [(4, 5), (6, 7), ...]  # HOW TO GET NON_EDGES OF HUGE FILE DO I NEED TO GENERATE THEM MYSELF???\n",
        "\n",
        "roc_auc_score = link_prediction(netmf_embedding, edges, non_edges)\n",
        "print(f\"ROC-AUC Score: {roc_auc_score}\")\n",
        "\n",
        "#TODO: current ROC-AUC score is too low, need to re-think method..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
