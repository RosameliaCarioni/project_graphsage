{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7c18JmeSuZW"
      },
      "source": [
        "https://medium.com/analytics-vidhya/ohmygraphs-graphsage-in-pyg-598b5ec77e7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O90RfNPbNn8g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Reddit\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import SAGEConv\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "import copy\n",
        "from tqdm import tqdm \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "from torch_geometric.transforms import RandomLinkSplit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.backends.mps.is_available() and False:\n",
        "    device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=device)\n",
        "    print (x)\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data: CORA - small version "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "data = data.to(device)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Information from graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print information about the dataset\n",
        "print(f'Dataset: {dataset}')\n",
        "print('-------------------')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of nodes: {data.x.shape[0]}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "# Print information about the graph\n",
        "print(f'\\nGraph:')\n",
        "print('------')\n",
        "print(f'Training nodes: {sum(data.train_mask).item()}')\n",
        "print(f'Evaluation nodes: {sum(data.val_mask).item()}')\n",
        "print(f'Test nodes: {sum(data.test_mask).item()}')\n",
        "print(f'Edges are directed: {data.is_directed()}')\n",
        "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Graph has loops: {data.has_self_loops()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate = 0.0001 # variable to change/play around with for experiments\n",
        "epochs = 10\n",
        "aggregator = 'mean' # variable to change/play around with for experiments\n",
        "dropout_rate = 0.4\n",
        "normalization = True\n",
        "activation_function = True\n",
        "bias = True\n",
        "batch =  512\n",
        "neighborhood_1 = 25\n",
        "neighborhood_2 = 10\n",
        "embedding_dimension = 128"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split data \n",
        "https://medium.com/stanford-cs224w/a-tour-of-pygs-data-loaders-9f2384e48f8f\n",
        "\n",
        "https://zqfang.github.io/2021-08-12-graph-linkpredict/ --> trasductie disjoint mode "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = RandomLinkSplit(\n",
        "    num_val=0.2,  # fraction of data held out for validation\n",
        "    num_test=0.2, # fraction of data held out for test\n",
        "    is_undirected= True, \n",
        "    add_negative_train_samples= True, \n",
        "    neg_sampling_ratio= 1.0, # Need to include negative sampling edges, the edges not existed in the original graph.\n",
        "    key = 'edge_label', \n",
        "    disjoint_train_ratio = 0.9\n",
        ")\n",
        "train_data, val_data, test_data = transform(data)\n",
        "train_data, val_data, test_data =  train_data.to(device), val_data.to(device), test_data.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NeighborLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = LinkNeighborLoader(train_data, \n",
        "                            num_neighbors=[neighborhood_1, neighborhood_2],\n",
        "                            shuffle=True,\n",
        "                            neg_sampling_ratio= 1.0, \n",
        "                            batch_size = batch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Information from sampling/subgraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print each subgraph\n",
        "for i, subgraph in enumerate(train_loader):\n",
        "    print(f'Subgraph {i}: {subgraph}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Make model for Link prediction\n",
        "\n",
        "Initialization:\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html\n",
        "\n",
        "https://medium.com/@juyi.lin/neighborloader-introduction-ccb870cc7294\n",
        "\n",
        "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(pred_y, y): \n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(pred_y, y)\n",
        "\n",
        "    train_acc = clf.score(out[data.train_mask], data.y[data.train_mask]) \n",
        "\n",
        "    return ((pred_y == y).sum()/len(y)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphSAGE_local(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout, aggr='mean', normalization = True, activation_function = True, bias = True):\n",
        "\n",
        "        super().__init__()\n",
        "        # as K = 2, we have 2 layers\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, out_channels = hidden_channels, project = activation_function, bias = bias)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels = out_channels, project = activation_function, bias = bias, normalize = normalization)\n",
        "\n",
        "    def forward(self, matrix_nodes_features, edge_index):\n",
        "      # matrix_nodes_features is a matrix from the data where row = nodes, columns = feature\n",
        "      # edge_index: This is a tensor that describes the connectivity of the graph. Each column in this matrix represents an edge. The first row contains the indices of the source nodes, and the second row contains the indices of the target nodes.\n",
        "    \n",
        "        x = self.conv1(matrix_nodes_features, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "\n",
        "        # returning only x allows to apply any task-specific post-processing (in this case: link prediction and node classification)\n",
        "        return x \n",
        "    \n",
        "    def fit(self, loader, epochs):\n",
        "        times = []\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        criterion = F.binary_cross_entropy_with_logits()\n",
        "\n",
        "        for epoch in range(1, epochs):\n",
        "            start = time.time()\n",
        "            train_loss, train_acc, val_loss, val_acc = 0, 0, 0, 0 \n",
        "\n",
        "            for batch in train_loader:\n",
        "                batch = batch.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                h = self(batch.x, batch.edge_index)\n",
        "                h_src = h[batch.edge_label_index[0]]\n",
        "                h_dst = h[batch.edge_label_index[1]]\n",
        "                pred = (h_src * h_dst).sum(dim=-1)\n",
        "\n",
        "                loss = criterion(pred, batch.edge_label)\n",
        "  \n",
        "                # Train data\n",
        "                train_loss += loss.item()\n",
        "                train_acc += accuracy(out[batch.train_mask].argmax(dim = 1), batch.y[batch.train_mask])\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += float(loss) * pred.size(0)\n",
        "\n",
        "\n",
        "\n",
        "            loss = train(model, optimizer, train_loader, device)\n",
        "            train_acc, val_acc, test_acc = test(model, data)\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
        "                  f'Val: {val_acc:.4f}, Train: {train_acc:.4f}, Test: {test_acc:.4f}')\n",
        "            \n",
        "            times.append(time.time() - start)\n",
        "        print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
        "\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm-wlKeK5VkW"
      },
      "source": [
        "# Train model with unsupervised loss \n",
        "Where model is trainned to fit training data \n",
        " The function iterates over batches of data from train_loader. Each batch contains a subset of the entire training dataset\n",
        " \n",
        " For each batch, the model computes the node embeddings h, then calculates the embeddings for the source h_src and destination h_dst nodes of each edge. It then predicts whether an edge should exist between node pairs (pred)\n",
        "\n",
        "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, device):\n",
        "    model.train() # set model into training mode, doesnt do anything else \n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        h = model(batch.x, batch.edge_index)\n",
        "        h_src = h[batch.edge_label_index[0]]\n",
        "        h_dst = h[batch.edge_label_index[1]]\n",
        "        \n",
        "        pred = (h_src * h_dst).sum(dim=-1)\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, batch.edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.size(0)\n",
        "\n",
        "    return total_loss / len(train_loader)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test method\n",
        "The test function evaluates the model's performance on unseen data. \n",
        "\n",
        "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    \n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    train_acc = clf.score(out[data.train_mask], data.y[data.train_mask]) \n",
        "    val_acc = clf.score(out[data.val_mask], data.y[data.val_mask]) \n",
        "    test_acc = clf.score(out[data.test_acc], data.y[data.test_mask])\n",
        "    return train_acc, val_acc, test_acc\n",
        "\n",
        "# TODO: this test maybe should return other things "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Running code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create GraphSAGE model for link prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GraphSAGE_local(\n",
            "  (conv1): SAGEConv(1433, 1433, aggr=mean)\n",
            "  (conv2): SAGEConv(1433, 128, aggr=mean)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = GraphSAGE_local(in_channels = data.num_node_features,\n",
        "                  hidden_channels= data.num_node_features,\n",
        "                  out_channels = embedding_dimension, # TODO: check results using 128 instead \n",
        "                  dropout= dropout_rate,\n",
        "                  aggr = aggregator,\n",
        "                  normalization = normalization,\n",
        "                  activation_function = activation_function,\n",
        "                  bias = bias)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Training model for certain number for epochs and testing it "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data(x=[2423, 1433], edge_index=[2, 7907], y=[2423], train_mask=[2423], val_mask=[2423], test_mask=[2423], n_id=[2423], e_id=[7907], input_id=[256], edge_label_index=[2, 512], edge_label=[512])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get results for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "out = model(data.x, data.edge_index).to(device)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(out[data.train_mask], data.y[data.train_mask])\n",
        "val_acc = clf.score(out[data.val_mask], data.y[data.val_mask])\n",
        "print(val_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JxEm6MvHzmAR",
        "DGzwcEMn5aWa"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
