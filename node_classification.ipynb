{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7c18JmeSuZW"
      },
      "source": [
        "https://medium.com/analytics-vidhya/ohmygraphs-graphsage-in-pyg-598b5ec77e7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O90RfNPbNn8g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Reddit\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.nn import SAGEConv\n",
        "import torch.nn.functional as F\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from torch_geometric.loader import NeighborLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4xFr0vIUEsm",
        "outputId": "e35b3c0c-9290-4d26-f9a6-7e17e1a60814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Use GPU if available\n",
        "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.], device='mps:0')\n"
          ]
        }
      ],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=mps_device)\n",
        "    print (x)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD1Ecy-8mem9"
      },
      "source": [
        "# Make model\n",
        "\n",
        "Initialization:\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_cuz1vcmeA0"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_dimension, out_dimension, dropout, aggr='mean', normalization = True, activation_function = True, bias = True):\n",
        "      # TODO: maybe activation_function should be False\n",
        "      # TODO: what should hidden_dimension be?\n",
        "\n",
        "        super().__init__()\n",
        "        # as K = 2, we have 2 layers\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels = in_dimension, out_channels = in_dimension, project = activation_function, bias = bias)\n",
        "        self.conv2 = SAGEConv(in_channels = in_dimension, out_channels = out_dimension, normalize = normalization, project = activation_function, bias = bias)\n",
        "\n",
        "    #def forward(self, matrix_nodes_feature, matrix_adj):\n",
        "    def forward(self, data):\n",
        "      # matrix_nodes_features = rows == nodes; columns == features\n",
        "      # matrix_adj = nodes * nodes\n",
        "      # data.x gives matrix where row = nodes, columns = feature\n",
        "        data = data.cuda()\n",
        "        #x = self.conv1(matrix_nodes_feature, matrix_adj)\n",
        "        x = self.conv1(data.x, data.adj_t)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        x = self.conv2(x, data.adj_t)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        return torch.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxEm6MvHzmAR"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxvlvQFtzzcg",
        "outputId": "00fe72a2-4841-4dfd-a0c9-eeba0a8c1e03"
      },
      "outputs": [],
      "source": [
        "dataset = PygNodePropPredDataset(name='ogbn-arxiv',\n",
        "                                 transform=T.ToSparseTensor())\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCcTP0CymU0U"
      },
      "source": [
        "Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoEcLjRnmTyx"
      },
      "outputs": [],
      "source": [
        "# this dataset comes with train-val-test splits predefined for benchmarking\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train'].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XQcKcrlN38O",
        "outputId": "2c5c5092-a0f1-4e31-fbe7-93199708d469"
      },
      "outputs": [],
      "source": [
        "print(f' dataset has {data.num_nodes} nodes where each node has a {data.num_node_features} dim feature vector')\n",
        "print(f' dataset has {data.num_edges} edges where each edge has a {data.num_edge_features} dim feature vector')\n",
        "print(f' dataset has {dataset.num_classes} classes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr0RqT23t797",
        "outputId": "e2f36afe-0b7b-4783-c6ed-975fae2ff966"
      },
      "outputs": [],
      "source": [
        "(data.adj_t).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7D-SNoJz67s"
      },
      "source": [
        "Check data into trin, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KjuWw6N0Ah9",
        "outputId": "92a79e56-1e0d-4ebb-ba1d-816e57c42a58"
      },
      "outputs": [],
      "source": [
        "print(split_idx['train'].shape)\n",
        "print(split_idx['valid'].shape)\n",
        "print(split_idx['test'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM_GLvguIHZK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUlWQsVuJkGk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvemvSExKbOg"
      },
      "source": [
        "# Data 2.0 Reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzRN_OjtKhJt"
      },
      "outputs": [],
      "source": [
        "dataset = Reddit(\"./\")\n",
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sUVB3aZLHi6"
      },
      "outputs": [],
      "source": [
        "train_idx = data.train_mask\n",
        "val_idx = data.val_mask\n",
        "test_idx = data.test_mask\n",
        "# Accessing feature and label data for each split\n",
        "X_train, y_train = data.x[train_idx], data.y[train_idx]\n",
        "X_val, y_val = data.x[val_idx], data.y[val_idx]\n",
        "X_test, y_test = data.x[test_idx], data.y[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrIq1tCbLQfi",
        "outputId": "5ce2fae3-94ee-4af6-8735-5a34d3f8e190"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NspByng_LpO6",
        "outputId": "c6c780e1-682f-417a-f420-e93713a2e870"
      },
      "outputs": [],
      "source": [
        "data = data.to(device, 'x', 'y')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCvxqz4J0KB4"
      },
      "source": [
        "# Train method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK3Nrf7A0-_2"
      },
      "outputs": [],
      "source": [
        "def train(model, data, train_idx, optimizer):\n",
        "  #TODO: check when to use validation set\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)[train_idx]\n",
        "    print (out.shape)\n",
        "    loss = F.nll_loss(out, data.y.squeeze(1)[train_idx]) #TODO: check for correct loss function\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGzwcEMn5aWa"
      },
      "source": [
        "# Test method\n",
        "TODO: check this shit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLJT7ssX5bvH"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad() # make sure that model doesn't change gradient\n",
        "def test(model, data, split_idx, evaluator):\n",
        "    model.eval()\n",
        "\n",
        "    out = model(data) # forward pass\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlbwtdtM12Hk"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVxVI6-R14nV"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0001\n",
        "epochs = 10\n",
        "output_dim = data.num_node_features\n",
        "aggregator = 'mean' # variable to change/play around with for experiments\n",
        "dropout_rate = 0.4\n",
        "normalization = True\n",
        "activation_function = True\n",
        "bias = True\n",
        "batch =  512\n",
        "neighborhood_1 = 25\n",
        "neighborhood_2 = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgef43HO3TB5"
      },
      "outputs": [],
      "source": [
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvsQcoTn3Zqd"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHTf6png0g8M"
      },
      "outputs": [],
      "source": [
        "model = GraphSAGE(in_dimension = data.num_node_features,\n",
        "                 out_dimension = output_dim,\n",
        "                  dropout= dropout_rate,\n",
        "                  aggr = aggregator,\n",
        "                  normalization = normalization,\n",
        "                  activation_function = activation_function,\n",
        "                  bias = bias)\n",
        "model = model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3nXG31EEowQ"
      },
      "source": [
        "# Create loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqnpZFZDEp8Z",
        "outputId": "bc57689a-1681-4a72-897f-90bfd8489f7c"
      },
      "outputs": [],
      "source": [
        "#from torch_sparse import SparseTensor\n",
        "\n",
        "#edge_index = data.edge_index\n",
        "#adj = SparseTensor(row=edge_index[0], col=edge_index[1], sparse_sizes=(data.num_nodes, data.num_nodes))\n",
        "\n",
        "# Update your data object\n",
        "#data.adj_t = adj\n",
        "\n",
        "#kwargs = {'batch_size': 1024, 'num_workers': 6, 'persistent_workers': True}\n",
        "#train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
        "#                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
        "\n",
        "loader = NeighborLoader(\n",
        "    data,\n",
        "    input_nodes = data.train_mask,\n",
        "    # Sample neighbors for each node for 2 iterations\n",
        "    num_neighbors =[neighborhood_1, neighborhood_2],\n",
        "    batch_size = batch,\n",
        "    shuffle = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFjAs7fSRjqb",
        "outputId": "fef13468-55f6-4ab5-c361-9c3f94c7ea97"
      },
      "outputs": [],
      "source": [
        "kwargs = {'batch_size': 1024, 'num_workers': 6, 'persistent_workers': True}\n",
        "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
        "                              num_neighbors=[25, 10], shuffle=True, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm-wlKeK5VkW"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "n5MC9h_b5XQC",
        "outputId": "cca6d061-ef90-4707-a83c-e58cddec60c2"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, 1 + epochs):\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad\n",
        "        train(model,batch,batch_idx,optimizer)\n",
        "\n",
        "        #optimizer.zero_grad()\n",
        "        #y = batch.y[:batch.batch_size]\n",
        "        #y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
        "        #loss = F.cross_entropy(y_hat, y)\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "\n",
        "    #loss = train(model, data, train_idx, optimizer)\n",
        "    #result = test(model, data, split_idx, evaluator)\n",
        "    #logger.add_result(run, result)\n",
        "\n",
        "        #train_acc, valid_acc, test_acc = result\n",
        "        print(f'Epoch: {epoch}/{epochs}, '\n",
        "          f'Loss: {loss:.4f}, ')\n",
        "              #f'Train: {100 * train_acc:.2f}%, '\n",
        "              #f'Valid: {100 * valid_acc:.2f}% '\n",
        "              #f'Test: {100 * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqNIQD7fEAE3"
      },
      "outputs": [],
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():   # No need for keepnig track of necessary changes to the gradient.\n",
        "  for data in test_dl:\n",
        "    X, y = data\n",
        "    output = net(X)\n",
        "    for idx, val in enumerate(output):\n",
        "      if torch.argmax(val) == y[idx]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "  print('Accuracy:', round(correct/total, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luf2S1Zix6MS"
      },
      "outputs": [],
      "source": [
        "#GPT\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.data import NeighborSampler\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "# Load a dataset (e.g., Cora)\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "# Create the model with the number of features and classes from the dataset\n",
        "model = GraphSAGE(dataset.num_node_features, 128, dataset.num_classes)\n",
        "\n",
        "# Define the NeighborSampler\n",
        "loader = NeighborSampler(data.edge_index, node_idx=None,\n",
        "                         sizes=[10, 10], batch_size=128,\n",
        "                         shuffle=True, num_workers=4)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "# Move model to GPU if available, set to training mode\n",
        "model.train()\n",
        "\n",
        "# Training loop\n",
        "for batch_size, n_id, adjs in loader:\n",
        "    # `adjs` is a list of `(edge_index, e_id, size)` tuples.\n",
        "    adjs = [adj.to(device) for adj in adjs]  # Move adjs to the correct device\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x[n_id], adjs)  # Perform a single forward pass.\n",
        "    loss = F.nll_loss(out, data.y[n_id[:batch_size]])  # Compute the loss solely based on the nodes in the current batch.\n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "\n",
        "    print(f'Loss: {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woux7nm6dmkN",
        "outputId": "61be0f1c-7158-40ba-c39d-3503ddeaaf01"
      },
      "outputs": [],
      "source": [
        "(data.x).shape\n",
        " # node features matrix, where: row = node, column = feature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmE48hgEUkMe"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPrlrMQEUt96",
        "outputId": "0993acb7-3b26-4962-ac84-a9b52f1d5d3b"
      },
      "outputs": [],
      "source": [
        "dataset = Reddit(\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNUpo7-pU7QX"
      },
      "outputs": [],
      "source": [
        "data = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbdR2LOFU-jI",
        "outputId": "c85653f2-35f1-415c-fe51-39b231ced580"
      },
      "outputs": [],
      "source": [
        "print(data.x) #nodes features, where row = node's feature vector.\n",
        "print()\n",
        "print(data.y) #nodes labels\n",
        "print()\n",
        "print(data.edge_index) #adjacency information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO3K-QSVVjL7"
      },
      "outputs": [],
      "source": [
        "G = to_networkx(data, to_undirected=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "-qqJsYOoV71t",
        "outputId": "a6fe8552-07bd-4a50-ff8a-e95bf23cf8b5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "nx.draw(G, with_labels=True, node_color=[[.7, .7, .7]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH90F_sfV9kk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JxEm6MvHzmAR",
        "DGzwcEMn5aWa"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
