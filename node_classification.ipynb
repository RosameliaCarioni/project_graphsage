{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is highly inspired in the following repositories: \n",
    "\n",
    "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py\n",
    "\n",
    "https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/blob/main/Chapter08/chapter8.ipynb \n",
    "\n",
    "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import time\n",
    "from sklearn.metrics import f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available() and False:\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print (x)\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: CORA - small version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "data = data.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Information from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Training nodes: {sum(data.train_mask).item()}')\n",
    "print(f'Evaluation nodes: {sum(data.val_mask).item()}')\n",
    "print(f'Test nodes: {sum(data.test_mask).item()}')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 # variable to change/play around with for experiments --> 0.0001\n",
    "epochs = 10\n",
    "aggregator = 'mean' # variable to change/play around with for experiments\n",
    "dropout_rate = 0.4\n",
    "normalization = True\n",
    "activation_function = True\n",
    "bias = True\n",
    "batch =  512\n",
    "neighborhood_1 = 25\n",
    "neighborhood_2 = 10\n",
    "embedding_dimension = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(data, \n",
    "                            input_nodes=data.train_mask, # ensure that the sampling only happens in the training set \n",
    "                            batch_size = batch,\n",
    "                            num_neighbors=[neighborhood_1, neighborhood_2], \n",
    "                            shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Information from sampling/subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each subgraph\n",
    "for i, subgraph in enumerate(train_loader):\n",
    "    print(f'Subgraph {i}: {subgraph}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make model for Link prediction\n",
    "\n",
    "Initialization:\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html\n",
    "\n",
    "https://medium.com/@juyi.lin/neighborloader-introduction-ccb870cc7294\n",
    "\n",
    "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py\n",
    "\n",
    "https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/blob/main/Chapter08/chapter8.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred_y, y): \n",
    "    return ((pred_y == y).sum()/len(y)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE_local(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout, aggr='mean', normalization = True, activation_function = True, bias = True):\n",
    "\n",
    "        super().__init__()\n",
    "        # as K = 2, we have 2 layers\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGEConv(in_channels, out_channels = hidden_channels, project = activation_function, bias = bias)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels = out_channels, project = activation_function, bias = bias, normalization = normalization)\n",
    "    \n",
    "\n",
    "    def forward(self, matrix_nodes_features, edge_index):\n",
    "      # matrix_nodes_features is a matrix from the data where row = nodes, columns = feature\n",
    "      # edge_index: This is a tensor that describes the connectivity of the graph. Each column in this matrix represents an edge. The first row contains the indices of the source nodes, and the second row contains the indices of the target nodes.\n",
    "    \n",
    "        h = self.conv1(matrix_nodes_features, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training = self.training)\n",
    "\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.relu(h) # TODO: maybe remove this \n",
    "        h = F.dropout(h,  p=self.dropout, training = self.training) # TODO: maybe remove this\n",
    "        h = F.log_softmax(h, dim = 1)\n",
    "        return h\n",
    "    \n",
    "    def fit(self, loader, epochs):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.train()\n",
    "        times = []\n",
    "\n",
    "        for epoch in range(epochs+1):\n",
    "            start = time.time()\n",
    "            train_loss, train_acc, val_loss, val_acc = 0, 0, 0, 0 \n",
    "            \n",
    "            for batch in loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = self(batch.x, batch.edge_index) # obtain the probability of belonging to each class or label for each node \n",
    "                \n",
    "                loss = criterion(out[batch.train_mask],  batch.y[batch.train_mask]) \n",
    "                \n",
    "                # Train data\n",
    "                train_loss += loss.item()\n",
    "                train_acc += accuracy(out[batch.train_mask].argmax(dim = 1), batch.y[batch.train_mask])\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Validation data\n",
    "                val_loss += criterion(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "                val_acc += accuracy((out[batch.val_mask]).argmax(dim = 1), batch.y[batch.val_mask]) \n",
    "\n",
    "            # All following values are average per batch \n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {loss/len(loader):.3f} | Train Acc: {train_acc/len(loader)*100:>6.2f}% | Val Loss: {val_loss/len(train_loader):.2f} | Val Acc: {val_acc/len(train_loader)*100:.2f}%')\n",
    "          \n",
    "            times.append(time.time() - start)\n",
    "        print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, data.edge_index)\n",
    "        y = data.y[data.test_mask]\n",
    "        y_prediction = out.argmax(dim = 1)[data.test_mask]\n",
    "\n",
    "        acc = accuracy(y_prediction, y)\n",
    "        f1_macro = f1_score(y, y_prediction, average = 'macro')\n",
    "        f1_micro =  f1_score(y, y_prediction, average = 'micro')\n",
    "        return acc, f1_macro, f1_micro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test method\n",
    "The test function evaluates the model's performance on unseen data. \n",
    "\n",
    "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create model for node classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE_local(\n",
      "  (conv1): SAGEConv(1433, 128, aggr=mean)\n",
      "  (conv2): SAGEConv(128, 7, aggr=mean)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "labels_all_nodes = data.y\n",
    "number_classes  = labels_all_nodes.unique().size(0)\n",
    "\n",
    "model = GraphSAGE_local(in_channels = data.num_node_features,\n",
    "                  hidden_channels= embedding_dimension,\n",
    "                  out_channels = number_classes,\n",
    "                  dropout= dropout_rate,\n",
    "                  aggr = aggregator,\n",
    "                  normalization = normalization,\n",
    "                  activation_function = activation_function,\n",
    "                  bias = bias)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training mdel for certain number of epochs and testing it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.948 | Train Acc:  12.14% | Val Loss: 1.95 | Val Acc: 16.02%\n",
      "Epoch   1 | Train Loss: 1.920 | Train Acc:  16.43% | Val Loss: 1.94 | Val Acc: 23.48%\n",
      "Epoch   2 | Train Loss: 1.828 | Train Acc:  25.00% | Val Loss: 1.90 | Val Acc: 20.43%\n",
      "Epoch   3 | Train Loss: 1.753 | Train Acc:  26.43% | Val Loss: 1.86 | Val Acc: 25.54%\n",
      "Epoch   4 | Train Loss: 1.730 | Train Acc:  36.43% | Val Loss: 1.87 | Val Acc: 28.70%\n",
      "Epoch   5 | Train Loss: 1.406 | Train Acc:  46.43% | Val Loss: 1.82 | Val Acc: 33.33%\n",
      "Epoch   6 | Train Loss: 1.400 | Train Acc:  40.71% | Val Loss: 1.80 | Val Acc: 32.89%\n",
      "Epoch   7 | Train Loss: 1.207 | Train Acc:  48.57% | Val Loss: 1.73 | Val Acc: 39.22%\n",
      "Epoch   8 | Train Loss: 1.210 | Train Acc:  49.29% | Val Loss: 1.68 | Val Acc: 41.49%\n",
      "Epoch   9 | Train Loss: 1.275 | Train Acc:  41.43% | Val Loss: 1.69 | Val Acc: 37.87%\n",
      "Epoch  10 | Train Loss: 1.009 | Train Acc:  54.29% | Val Loss: 1.61 | Val Acc: 41.70%\n",
      "Median time per epoch: 0.0339s\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, epochs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate accuracy on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuarcy: 59.50%\n",
      "Model f1 Macro: 0.47%\n",
      "Model f1 Micro: 0.59%\n"
     ]
    }
   ],
   "source": [
    "acc, f1_macro, f1_micro = model.test(data)\n",
    "print(f'Model accuarcy: {acc*100:.2f}%' )\n",
    "print(f'Model f1 Macro: {f1_macro:.2f}%' )\n",
    "print(f'Model f1 Micro: {f1_micro:.2f}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_sage_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
