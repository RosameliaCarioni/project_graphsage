{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is inspired/based in the following work: \n",
    "\n",
    "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py\n",
    "\n",
    "https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/blob/main/Chapter08/chapter8.ipynb \n",
    "\n",
    "https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup.py\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html\n",
    "\n",
    "https://medium.com/@juyi.lin/neighborloader-introduction-ccb870cc7294"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import time\n",
    "from sklearn.metrics import f1_score \n",
    "import numpy as np\n",
    "\n",
    "# Local \n",
    "import graph_handler\n",
    "import graph_sage_node_classification\n",
    "from k_cross_validation import k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available() and False:\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print (x)\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data: CORA - small version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "data = data.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Information from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "-------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Training nodes: 140\n",
      "Evaluation nodes: 500\n",
      "Test nodes: 1000\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "source": [
    "graph_handler.visualize_information_graph(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES TO CHANGE FOR EXPERIMENTS \n",
    "learning_rate = 0.01 # variable to change/play around with for experiments --> 0.0001\n",
    "aggregator = 'mean' # variable to change/play around with for experiments\n",
    "\n",
    "# FIXED PARAMETERS\n",
    "epochs = 10\n",
    "dropout_rate = 0.4\n",
    "normalization = True\n",
    "activation_function = True\n",
    "bias = True\n",
    "batch =  512\n",
    "neighborhood_1 = 25\n",
    "neighborhood_2 = 10\n",
    "embedding_dimension = 128\n",
    "k = 5 # k-cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model and obtaining results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the metrics for each fold\n",
    "micro_f1_scores, macro_f1_scores, accuracy_scores = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold =  0\n",
      "Epoch   0 | Train Loss: 2.045 | Train Acc:  19.02% | Val Loss: 2.00 | Val Acc: 17.20%\n",
      "Epoch   1 | Train Loss: 1.777 | Train Acc:  30.51% | Val Loss: 1.91 | Val Acc: 18.05%\n",
      "Epoch   2 | Train Loss: 1.477 | Train Acc:  41.80% | Val Loss: 1.83 | Val Acc: 22.40%\n",
      "Epoch   3 | Train Loss: 1.258 | Train Acc:  49.85% | Val Loss: 1.74 | Val Acc: 28.58%\n",
      "Epoch   4 | Train Loss: 1.099 | Train Acc:  53.70% | Val Loss: 1.61 | Val Acc: 35.87%\n",
      "Epoch   5 | Train Loss: 0.999 | Train Acc:  58.94% | Val Loss: 1.60 | Val Acc: 38.21%\n",
      "Epoch   6 | Train Loss: 1.065 | Train Acc:  54.03% | Val Loss: 1.63 | Val Acc: 35.77%\n",
      "Epoch   7 | Train Loss: 0.928 | Train Acc:  58.88% | Val Loss: 1.61 | Val Acc: 36.14%\n",
      "Epoch   8 | Train Loss: 0.979 | Train Acc:  55.52% | Val Loss: 1.61 | Val Acc: 38.64%\n",
      "Epoch   9 | Train Loss: 1.038 | Train Acc:  54.95% | Val Loss: 1.62 | Val Acc: 39.04%\n",
      "Epoch  10 | Train Loss: 0.943 | Train Acc:  58.32% | Val Loss: 1.66 | Val Acc: 38.43%\n",
      "Median time per epoch: 0.1868s\n",
      "Fold =  1\n",
      "Epoch   0 | Train Loss: 1.887 | Train Acc:  27.30% | Val Loss: 1.99 | Val Acc: 17.04%\n",
      "Epoch   1 | Train Loss: 1.593 | Train Acc:  37.57% | Val Loss: 1.83 | Val Acc: 25.07%\n",
      "Epoch   2 | Train Loss: 1.285 | Train Acc:  49.77% | Val Loss: 1.72 | Val Acc: 38.06%\n",
      "Epoch   3 | Train Loss: 1.218 | Train Acc:  51.23% | Val Loss: 1.61 | Val Acc: 39.70%\n",
      "Epoch   4 | Train Loss: 1.017 | Train Acc:  55.77% | Val Loss: 1.61 | Val Acc: 40.90%\n",
      "Epoch   5 | Train Loss: 0.915 | Train Acc:  59.90% | Val Loss: 1.60 | Val Acc: 42.09%\n",
      "Epoch   6 | Train Loss: 0.967 | Train Acc:  57.14% | Val Loss: 1.54 | Val Acc: 43.85%\n",
      "Epoch   7 | Train Loss: 0.873 | Train Acc:  62.49% | Val Loss: 1.55 | Val Acc: 41.60%\n",
      "Epoch   8 | Train Loss: 0.921 | Train Acc:  58.88% | Val Loss: 1.62 | Val Acc: 40.55%\n",
      "Epoch   9 | Train Loss: 0.983 | Train Acc:  57.39% | Val Loss: 1.66 | Val Acc: 39.25%\n",
      "Epoch  10 | Train Loss: 0.946 | Train Acc:  58.44% | Val Loss: 1.66 | Val Acc: 42.40%\n",
      "Median time per epoch: 0.1793s\n",
      "Fold =  2\n",
      "Epoch   0 | Train Loss: 1.912 | Train Acc:  21.05% | Val Loss: 1.95 | Val Acc: 16.15%\n",
      "Epoch   1 | Train Loss: 1.586 | Train Acc:  37.52% | Val Loss: 1.83 | Val Acc: 24.56%\n",
      "Epoch   2 | Train Loss: 1.304 | Train Acc:  48.28% | Val Loss: 1.73 | Val Acc: 31.00%\n",
      "Epoch   3 | Train Loss: 1.194 | Train Acc:  50.34% | Val Loss: 1.78 | Val Acc: 33.23%\n",
      "Epoch   4 | Train Loss: 1.095 | Train Acc:  53.34% | Val Loss: 1.73 | Val Acc: 34.72%\n",
      "Epoch   5 | Train Loss: 0.992 | Train Acc:  57.56% | Val Loss: 1.73 | Val Acc: 36.11%\n",
      "Epoch   6 | Train Loss: 1.024 | Train Acc:  55.23% | Val Loss: 1.70 | Val Acc: 36.14%\n",
      "Epoch   7 | Train Loss: 1.000 | Train Acc:  57.34% | Val Loss: 1.75 | Val Acc: 35.42%\n",
      "Epoch   8 | Train Loss: 0.992 | Train Acc:  55.97% | Val Loss: 1.66 | Val Acc: 38.87%\n",
      "Epoch   9 | Train Loss: 0.883 | Train Acc:  60.86% | Val Loss: 1.72 | Val Acc: 38.27%\n",
      "Epoch  10 | Train Loss: 0.942 | Train Acc:  56.22% | Val Loss: 1.66 | Val Acc: 37.89%\n",
      "Median time per epoch: 0.1758s\n",
      "Fold =  3\n",
      "Epoch   0 | Train Loss: 1.824 | Train Acc:  24.38% | Val Loss: 1.96 | Val Acc: 11.92%\n",
      "Epoch   1 | Train Loss: 1.620 | Train Acc:  30.79% | Val Loss: 1.88 | Val Acc: 19.58%\n",
      "Epoch   2 | Train Loss: 1.460 | Train Acc:  37.55% | Val Loss: 1.83 | Val Acc: 22.29%\n",
      "Epoch   3 | Train Loss: 1.361 | Train Acc:  43.12% | Val Loss: 1.85 | Val Acc: 23.74%\n",
      "Epoch   4 | Train Loss: 1.311 | Train Acc:  40.62% | Val Loss: 1.95 | Val Acc: 26.66%\n",
      "Epoch   5 | Train Loss: 1.318 | Train Acc:  43.38% | Val Loss: 1.93 | Val Acc: 26.55%\n",
      "Epoch   6 | Train Loss: 1.140 | Train Acc:  51.51% | Val Loss: 1.88 | Val Acc: 32.78%\n",
      "Epoch   7 | Train Loss: 1.109 | Train Acc:  54.36% | Val Loss: 1.83 | Val Acc: 35.75%\n",
      "Epoch   8 | Train Loss: 1.061 | Train Acc:  56.90% | Val Loss: 1.69 | Val Acc: 37.18%\n",
      "Epoch   9 | Train Loss: 1.028 | Train Acc:  54.51% | Val Loss: 1.73 | Val Acc: 36.17%\n",
      "Epoch  10 | Train Loss: 1.032 | Train Acc:  56.14% | Val Loss: 1.72 | Val Acc: 36.87%\n",
      "Median time per epoch: 0.1760s\n",
      "Fold =  4\n",
      "Epoch   0 | Train Loss: 1.856 | Train Acc:  26.04% | Val Loss: 1.96 | Val Acc: 15.51%\n",
      "Epoch   1 | Train Loss: 1.664 | Train Acc:  35.73% | Val Loss: 1.84 | Val Acc: 26.35%\n",
      "Epoch   2 | Train Loss: 1.543 | Train Acc:  34.59% | Val Loss: 1.82 | Val Acc: 24.48%\n",
      "Epoch   3 | Train Loss: 1.494 | Train Acc:  37.66% | Val Loss: 1.77 | Val Acc: 28.05%\n",
      "Epoch   4 | Train Loss: 1.460 | Train Acc:  40.84% | Val Loss: 1.76 | Val Acc: 31.12%\n",
      "Epoch   5 | Train Loss: 1.396 | Train Acc:  42.71% | Val Loss: 1.77 | Val Acc: 29.24%\n",
      "Epoch   6 | Train Loss: 1.485 | Train Acc:  39.75% | Val Loss: 1.82 | Val Acc: 26.85%\n",
      "Epoch   7 | Train Loss: 1.432 | Train Acc:  39.92% | Val Loss: 1.81 | Val Acc: 27.93%\n",
      "Epoch   8 | Train Loss: 1.412 | Train Acc:  41.50% | Val Loss: 1.79 | Val Acc: 27.35%\n",
      "Epoch   9 | Train Loss: 1.424 | Train Acc:  44.23% | Val Loss: 1.81 | Val Acc: 28.79%\n",
      "Epoch  10 | Train Loss: 1.505 | Train Acc:  39.23% | Val Loss: 1.81 | Val Acc: 28.06%\n",
      "Median time per epoch: 0.1835s\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, test_idx, val_idx) in enumerate(zip(*k_fold(data, k))):\n",
    "    print('Fold = ', fold)\n",
    "    # Create masks used to access data \n",
    "    mask_train = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    mask_train[train_idx] = True\n",
    "    mask_test = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    mask_test[test_idx] = True\n",
    "\n",
    "    # Create a NeighborLoader which samples nodes for the current fold's training data\n",
    "    train_loader = NeighborLoader(data, \n",
    "                                  input_nodes = mask_train, \n",
    "                                  batch_size=batch,\n",
    "                                  num_neighbors=[neighborhood_1, neighborhood_2],\n",
    "                                  shuffle=True)\n",
    "\n",
    "    # Initialize model and optimizer for each fold\n",
    "    model = graph_sage_node_classification.GraphSAGE_local(in_channels = data.num_node_features,\n",
    "                      hidden_channels= embedding_dimension,\n",
    "                      out_channels = dataset.num_classes,\n",
    "                      dropout= dropout_rate,\n",
    "                      aggr = aggregator,\n",
    "                      normalization = normalization,\n",
    "                      activation_function = activation_function,\n",
    "                      bias = bias)\n",
    "    model.to(device)\n",
    "\n",
    "    # Train the model for the current fold\n",
    "    model.fit(train_loader, epochs, learning_rate, device)\n",
    "\n",
    "    # Obtain results for test data \n",
    "    acc, f1_macro, f1_micro = model.test_kfold(data, mask_test)\n",
    "\n",
    "    # Store results \n",
    "    micro_f1_scores.append(f1_micro)\n",
    "    macro_f1_scores.append(f1_macro)\n",
    "    accuracy_scores.append(acc)\n",
    "    \n",
    "# Get the mean from the results \n",
    "mean_micro_f1 = np.mean(micro_f1_scores)\n",
    "mean_macro_f1 = np.mean(macro_f1_scores)\n",
    "mean_accuracy = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.17680119499901\n",
      "56.745100747539944\n",
      "59.17680159211158\n"
     ]
    }
   ],
   "source": [
    "print(mean_micro_f1*100)\n",
    "print(mean_macro_f1*100)\n",
    "print(mean_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_sage_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
