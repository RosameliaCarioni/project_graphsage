{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphsage_calculate_embeddings\n",
    "import test_embeddings\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.00002, 0.0001, 0.001] # variable to change/play around with for experiments --> 0.0001\n",
    "aggregators = ['MeanAggregation'] # variable to change/play around with for experiments\n",
    "directed_graph = True\n",
    "\n",
    "# FIXED PARAMS \n",
    "epochs = 10\n",
    "dropout_rate = 0.4\n",
    "normalization = True \n",
    "activation_function = F.relu\n",
    "bias = True\n",
    "batch_size =  512\n",
    "neighborhood_1 = 25\n",
    "neighborhood_2 = 10\n",
    "embedding_dimension = 128\n",
    "hidden_layer = 512\n",
    "project = True # layer applies a linear transformation followed by an activation function before aggreagation, as described in EQ. 3 of paper "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001 # variable to change/play around with for experiments --> 0.0001\n",
    "aggregator = 'map' # variable to change/play around with for experiments [mean, ]\n",
    "directed_graph = False\n",
    "\n",
    "# FIXED PARAMS \n",
    "epochs = 10\n",
    "dropout_rate = 0.4\n",
    "normalization = True \n",
    "activation_function = F.relu\n",
    "bias = True\n",
    "batch_size =  512\n",
    "neighborhood_1 = 25\n",
    "neighborhood_2 = 10\n",
    "embedding_dimension = 128\n",
    "hidden_layer = 512\n",
    "project = True # layer applies a linear transformation followed by an activation function before aggreagation, as described in EQ. 3 of paper "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_features, number_nodes = data.num_features, data.x.shape[0]\n",
    "data = data.sort(sort_by_row=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not resolve 'map' among choices {'MLPAggregation', 'StdAggregation', 'DeepSetsAggregation', 'EquilibriumAggregation', 'VarAggregation', 'AttentionalAggregation', 'SumAggregation', 'MinAggregation', 'GRUAggregation', 'MaxAggregation', 'MedianAggregation', 'GraphMultisetTransformer', 'Set2Set', 'SoftmaxAggregation', 'DegreeScalerAggregation', 'SetTransformerAggregation', 'MeanAggregation', 'LCMAggregation', 'QuantileAggregation', 'PowerMeanAggregation', 'MultiAggregation', 'Aggregation', 'LSTMAggregation', 'SortAggregation', 'add', 'MulAggregation'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embedding_matrix \u001b[39m=\u001b[39m graphsage_calculate_embeddings\u001b[39m.\u001b[39;49mcompute_embedding_matrix(\n\u001b[1;32m      2\u001b[0m     data \u001b[39m=\u001b[39;49m data,\n\u001b[1;32m      3\u001b[0m     number_features \u001b[39m=\u001b[39;49m number_features,\n\u001b[1;32m      4\u001b[0m     number_nodes \u001b[39m=\u001b[39;49m number_nodes,\n\u001b[1;32m      5\u001b[0m     batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[1;32m      6\u001b[0m     hidden_layer \u001b[39m=\u001b[39;49m hidden_layer, \n\u001b[1;32m      7\u001b[0m     epochs \u001b[39m=\u001b[39;49m epochs, \n\u001b[1;32m      8\u001b[0m     neighborhood_1 \u001b[39m=\u001b[39;49m neighborhood_1,\n\u001b[1;32m      9\u001b[0m     neighborhood_2 \u001b[39m=\u001b[39;49m neighborhood_2,\n\u001b[1;32m     10\u001b[0m     embedding_dimension \u001b[39m=\u001b[39;49m embedding_dimension,\n\u001b[1;32m     11\u001b[0m     learning_rate \u001b[39m=\u001b[39;49m learning_rate,\n\u001b[1;32m     12\u001b[0m     dropout_rate \u001b[39m=\u001b[39;49m dropout_rate,\n\u001b[1;32m     13\u001b[0m     activation_function \u001b[39m=\u001b[39;49m activation_function,\n\u001b[1;32m     14\u001b[0m     aggregator \u001b[39m=\u001b[39;49m aggregator,\n\u001b[1;32m     15\u001b[0m     activation_before_normalization \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m     16\u001b[0m     bias\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     17\u001b[0m     normalize \u001b[39m=\u001b[39;49m normalization, \n\u001b[1;32m     18\u001b[0m     project \u001b[39m=\u001b[39;49m project\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m~/University/MSc/1_year/2_period/advanced_ml/project_graphsage/graphsage_calculate_embeddings.py:55\u001b[0m, in \u001b[0;36mcompute_embedding_matrix\u001b[0;34m(data, number_features, number_nodes, batch_size, hidden_layer, epochs, neighborhood_1, neighborhood_2, embedding_dimension, learning_rate, dropout_rate, activation_function, aggregator, activation_before_normalization, bias, project, normalize)\u001b[0m\n\u001b[1;32m     52\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[39m# Create model\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m model \u001b[39m=\u001b[39m GraphSAGE(\n\u001b[1;32m     56\u001b[0m     in_channels\u001b[39m=\u001b[39;49mnumber_features,\n\u001b[1;32m     57\u001b[0m     hidden_channels\u001b[39m=\u001b[39;49mhidden_layer,  \u001b[39m# TODO: not sure\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m     out_channels\u001b[39m=\u001b[39;49membedding_dimension,\n\u001b[1;32m     59\u001b[0m     num_layers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     60\u001b[0m     aggr\u001b[39m=\u001b[39;49maggregator,\n\u001b[1;32m     61\u001b[0m     act\u001b[39m=\u001b[39;49mactivation_function,\n\u001b[1;32m     62\u001b[0m     dropout\u001b[39m=\u001b[39;49mdropout_rate,\n\u001b[1;32m     63\u001b[0m     act_first\u001b[39m=\u001b[39;49mactivation_before_normalization,\n\u001b[1;32m     64\u001b[0m     bias\u001b[39m=\u001b[39;49mbias,\n\u001b[1;32m     65\u001b[0m     normalize \u001b[39m=\u001b[39;49m normalize,\n\u001b[1;32m     66\u001b[0m     project \u001b[39m=\u001b[39;49m project\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m     72\u001b[0m times \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_sage_6/lib/python3.9/site-packages/torch_geometric/nn/models/basic_gnn.py:106\u001b[0m, in \u001b[0;36mBasicGNN.__init__\u001b[0;34m(self, in_channels, hidden_channels, num_layers, out_channels, dropout, act, act_first, act_kwargs, norm, norm_kwargs, jk, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs \u001b[39m=\u001b[39m ModuleList()\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m num_layers \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 106\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_conv(in_channels, hidden_channels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(in_channels, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[1;32m    108\u001b[0m         in_channels \u001b[39m=\u001b[39m (hidden_channels, hidden_channels)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_sage_6/lib/python3.9/site-packages/torch_geometric/nn/models/basic_gnn.py:580\u001b[0m, in \u001b[0;36mGraphSAGE.init_conv\u001b[0;34m(self, in_channels, out_channels, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_conv\u001b[39m(\u001b[39mself\u001b[39m, in_channels: Union[\u001b[39mint\u001b[39m, Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]],\n\u001b[1;32m    579\u001b[0m               out_channels: \u001b[39mint\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m MessagePassing:\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mreturn\u001b[39;00m SAGEConv(in_channels, out_channels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_sage_6/lib/python3.9/site-packages/torch_geometric/nn/conv/sage_conv.py:91\u001b[0m, in \u001b[0;36mSAGEConv.__init__\u001b[0;34m(self, in_channels, out_channels, aggr, normalize, root_weight, project, bias, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39maggr_kwargs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39min_channels\u001b[39m\u001b[39m'\u001b[39m, in_channels[\u001b[39m0\u001b[39m])\n\u001b[1;32m     89\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39maggr_kwargs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mout_channels\u001b[39m\u001b[39m'\u001b[39m, in_channels[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 91\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(aggr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject:\n\u001b[1;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m in_channels[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_sage_6/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:138\u001b[0m, in \u001b[0;36mMessagePassing.__init__\u001b[0;34m(self, aggr, aggr_kwargs, flow, node_dim, decomposed_layers, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(aggr, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggr \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m aggr]\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggr_module \u001b[39m=\u001b[39m aggr_resolver(aggr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(aggr_kwargs \u001b[39mor\u001b[39;49;00m {}))\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow \u001b[39m=\u001b[39m flow\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m flow \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39msource_to_target\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtarget_to_source\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_sage_6/lib/python3.9/site-packages/torch_geometric/nn/resolver.py:77\u001b[0m, in \u001b[0;36maggregation_resolver\u001b[0;34m(query, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m aggrs \u001b[39m=\u001b[39m [\n\u001b[1;32m     71\u001b[0m     aggr \u001b[39mfor\u001b[39;00m aggr \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(aggr)\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(aggr, \u001b[39mtype\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(aggr, base_cls)\n\u001b[1;32m     73\u001b[0m ]\n\u001b[1;32m     74\u001b[0m aggr_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     75\u001b[0m     \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m: aggr\u001b[39m.\u001b[39mSumAggregation,\n\u001b[1;32m     76\u001b[0m }\n\u001b[0;32m---> 77\u001b[0m \u001b[39mreturn\u001b[39;00m resolver(aggrs, aggr_dict, query, base_cls, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph_sage_6/lib/python3.9/site-packages/torch_geometric/resolver.py:37\u001b[0m, in \u001b[0;36mresolver\u001b[0;34m(classes, class_dict, query, base_cls, base_cls_repr, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n\u001b[1;32m     36\u001b[0m choices \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m classes) \u001b[39m|\u001b[39m \u001b[39mset\u001b[39m(class_dict\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m---> 37\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not resolve \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m among choices \u001b[39m\u001b[39m{\u001b[39;00mchoices\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not resolve 'map' among choices {'MLPAggregation', 'StdAggregation', 'DeepSetsAggregation', 'EquilibriumAggregation', 'VarAggregation', 'AttentionalAggregation', 'SumAggregation', 'MinAggregation', 'GRUAggregation', 'MaxAggregation', 'MedianAggregation', 'GraphMultisetTransformer', 'Set2Set', 'SoftmaxAggregation', 'DegreeScalerAggregation', 'SetTransformerAggregation', 'MeanAggregation', 'LCMAggregation', 'QuantileAggregation', 'PowerMeanAggregation', 'MultiAggregation', 'Aggregation', 'LSTMAggregation', 'SortAggregation', 'add', 'MulAggregation'}"
     ]
    }
   ],
   "source": [
    "embedding_matrix = graphsage_calculate_embeddings.compute_embedding_matrix(\n",
    "    data = data,\n",
    "    number_features = number_features,\n",
    "    number_nodes = number_nodes,\n",
    "    batch_size = batch_size,\n",
    "    hidden_layer = hidden_layer, \n",
    "    epochs = epochs, \n",
    "    neighborhood_1 = neighborhood_1,\n",
    "    neighborhood_2 = neighborhood_2,\n",
    "    embedding_dimension = embedding_dimension,\n",
    "    learning_rate = learning_rate,\n",
    "    dropout_rate = dropout_rate,\n",
    "    activation_function = activation_function,\n",
    "    aggregator = aggregator,\n",
    "    activation_before_normalization = True, \n",
    "    bias= True,\n",
    "    normalize = normalization, \n",
    "    project = project\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embedding_matrix, 'embeddings/cora_small.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0451,  0.1460, -0.0826, -0.0099,  0.0114, -0.1437,  0.0257, -0.1041,\n",
      "        -0.1011, -0.0123, -0.1976, -0.0826, -0.0536,  0.0027,  0.0145,  0.0394,\n",
      "         0.0553,  0.0026,  0.0670,  0.0522, -0.0974, -0.0214,  0.0250,  0.1137,\n",
      "         0.0690,  0.1135, -0.0982,  0.0047, -0.0490,  0.0705, -0.0247,  0.1199,\n",
      "         0.0261,  0.0567,  0.0634,  0.0701, -0.0677,  0.0688, -0.0173, -0.0420,\n",
      "         0.1197, -0.0072, -0.1108, -0.1049,  0.0146,  0.1797,  0.1281,  0.0121,\n",
      "         0.0507,  0.0064, -0.0214, -0.1914,  0.0777, -0.0311,  0.1702,  0.0048,\n",
      "        -0.1450, -0.1631, -0.0918,  0.0491,  0.0470, -0.0891,  0.0744,  0.0032,\n",
      "         0.1197, -0.2080,  0.1173,  0.0876,  0.0270,  0.2183, -0.0878,  0.0212,\n",
      "         0.0602, -0.0598, -0.1275,  0.0259,  0.0396,  0.0113, -0.1043,  0.0663,\n",
      "        -0.0223, -0.0179,  0.0703,  0.0594, -0.0308,  0.0288, -0.0712,  0.1674,\n",
      "         0.1075,  0.0526, -0.1342,  0.1112,  0.0426,  0.0493, -0.0336,  0.2211,\n",
      "        -0.0116, -0.0613,  0.1108,  0.1838, -0.1739,  0.1119, -0.1172,  0.0286,\n",
      "        -0.0183,  0.0975, -0.0344, -0.0917,  0.1069, -0.0286,  0.0728,  0.0406,\n",
      "         0.0298,  0.1321,  0.0754,  0.0053,  0.0007, -0.0272,  0.0736, -0.0304,\n",
      "         0.0274, -0.0098, -0.0732,  0.0209, -0.1128,  0.0819,  0.0651,  0.0726],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# How to load it again: \n",
    "embedding_matrix = torch.load('embeddings/cora_small.pt')\n",
    "print(embedding_matrix[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate node classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1_macro, f1_micro = test_embeddings.test_node_classification_one_class(embedding_matrix, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.4631, F1_macro: 79.1748, F1_micro: 81.4631\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc*100:.4f}, F1_macro: {f1_macro*100:.4f}, F1_micro: {f1_micro*100:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform embedding matrix into numpy \n",
    "embedding_detached = embedding_matrix.detach()\n",
    "embedding_np = embedding_detached.numpy()\n",
    "\n",
    "# Obtain edges and non existing edges as lists \n",
    "edges, non_edges = test_embeddings.get_edges_and_non_edges_as_lists(data, directed_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration done\n"
     ]
    }
   ],
   "source": [
    "roc_auc = test_embeddings.test_link_prediction_k_fold_validation(embedding_matrix, edges, non_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 97.26912787390232\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC AUC Score:\", roc_auc*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_sage_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
